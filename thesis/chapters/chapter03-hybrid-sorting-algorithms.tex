\chapter{Przegląd hybrydowych algorytmów sortujących}
\thispagestyle{chapterBeginStyle}

\section{Główne sposoby modyfikacji algorytmów}
W celu poprawy wydajności algorytmów sortujących stosuje się ich modyfikacje oraz ulepszenia. W tej pracy wykorzystano dwa główne sposoby na usprawnienie algorytmów.\\

Pierwszym sposobem jest modyfikacja składowych danego algorytmu. Wiele spośród znanych algorytmów składa się z kilku osobnych kroków, z których każdy można wyekstrahować do oddzielnego procesu. Pomysł ten polega na modyfikacji składowych algorytmu sortującego w taki sposób, aby np. lepiej radził on sobie w przypadku pesymistycznym.\\

Drugim sposobem na ulepszenie jest próba połączenia wielu algorytmów sortujących. Niektóre algorytmy zachowują się lepiej dla stosunkowo małej ilości danych, inne zaś są znaczenie wydajniejsze przy rozbudowanym zbiorze danych wejściowych. Pomysł ten polega na opracowaniu algorytmu, którego działanie zmienia się w zależności od czynników zewnętrznych, np. długości danych do posortowania.\\

\section{Rodzina deterministycznych algorytmów Quick Sort}
Podczas analizy algorytmów sortujących z rodziny Quick Sort zostały przetestowane wariacje algorytmów z różnymi metodami partycjonowania oraz różnymi deterministycznymi metodami wyboru pivota. Do partycjonowania danych wejściowych wykorzystano poniższe metody:

\begin{itemize}
	\setlength\itemsep{0em}
	\item \BOLD{metoda Lemuto} - jest domyślnym algorytmem partycjonowania w projektowanym systemie. Tablica jest iterowana od pierwszego do ostatniego elementu. Elementy mniejsze od pivota są przenoszone na lewą część tablicy, zaś elementy większe od pivota na jej prawą część. Algorytm kończy się w momencie przeniesienia ostatniego elementu.
	\item \BOLD{metoda Hoarego} - tablica jest partycjonowana za pomocą dwóch iteratorów umieszczonych po przeciwnych stronach tablicy oraz skierowanych do jej środka. Pojedyncza iteracja trwa do momentu napotkania dwóch elementów, które nie znajdują się w odpowiednich częściach tablicy, tzn. element po lewej stronie jest większy od pivota, oraz element po prawej stronie jest mniejszy od pivota. Wtedy elementy znajdujące się w miejscu iteratorów są zamieniane miejscami oraz algorytm jest kontynuowany. Program kończy się w momencie spotkania obydwu iteratorów.
\end{itemize}

Wykonując testy brano pod uwagę następujące metody wyboru pivota:
\begin{itemize}
	\setlength\itemsep{0em}
	\item \BOLD{ostatni element} - pivotem jest ostatni element tablicy,
	\item \BOLD{mediana z trzech} - pivotem jest mediana z pierwszego, środkowego oraz ostatniego elementu tablicy,
	\item \BOLD{pseudo-mediana z dziewięciu} - pivotem jest mediana z dziewięciu równo oddalonych od siebie elementów, z których pierwszym jest pierwszy element tablicy, oraz ostatnim jest ostatni element tablicy,
	\item \BOLD{mediana-median z pięciu} - pivot jest medianą pięciu median obliczanych rekurencyjnie,
	\item \BOLD{mediana-median z trzech} - pivot jest medianą trzech median obliczanych rekurencyjnie.\\
\end{itemize}

\subsection{Analiza porównawcza algorytmów}

Analizując wydajność algorytmów z rodziny Quick Sort badano liczbę wykonywanych operacji atomowych z podziałem na operacje porównania, zamiany miejsc oraz przypisania. Dodatkowo badano łączny koszt wykonanych operacji jako sumę ważoną liczby operacji atomowych, z uwzględnieniem wartości współczynnika kosztu. Badając łączną liczbę wykonanych operacji założono stałą wartość współczynnika kosztu $\alpha = 1.0$.\\

Dla losowych danych wejściowych (\ref{fig:quick-sort-deterministic-pivot-random}), czyli przypadku średniego w klasycznym algorytmie Quick Sort, przy założeniu że operacja porównania jest czasowo równoważna operacji przypisania ($\alpha=1.0$), partycjonowanie metodą Hoarego jest wydajniejsze lub tak samo wydajne jak partycjonowanie metodą Lemuto. Najlepsze wyniki otrzymano poprzez połączenie partycjonowania metodą Hoarego z wyborem pivota jako ostatni element tablicy. Najgorsze wyniki otrzymano wybierając pivot jako mediana-median z pięciu, przy czym najgorszy wynik osiągnięto niezależnie od wyboru metody partycjonowania.\\

Dla danych wejściowych posortowanych w odwrotnej kolejności (\ref{fig:quick-sort-deterministic-pivot-reversed}), czyli dla przypadku pesymistycznego w klasycznym algorytmie Quick Sort, przy założeniu że operacja porównania jest czasowo równoważna operacji przypisania ($\alpha=1.0$), partycjonowanie metodą Hoarego jest również wydajniejsze lub tak samo wydajne jak partycjonowanie metodą Lemuto. Najlepsze wyniki otrzymano poprzez połączenie partycjonowania metodą Hoarego z wyborem pivota jako mediana z trzech. Najgorsze wyniki otrzymano dla klasycznego algorytmu Quick Sort, czyli poprzez połączenia partycjonowania metodą Lemuto z wyborem pivota jako ostatni element tablicy.\\

Analizując łączny koszt wykonanych operacji (\ref{fig:quick-sort-deterministic-pivot-cost-factor}) w zależności od wartości współczynnika kosztu $\alpha$ można zauważyć, że dla typów danych o współczynniku kosztu większym bądź równym wartości $\alpha = 2.0$, partycjonowanie metodą Lemuto jest wydajniejsze niż partycjonowanie metodą Hoare. Wyniki te można interpretować jako sortowanie struktur złożonych z co najmniej dwóch typów prostych. Najskuteczniejszą z badanych strategii sortowania jest partycjonowanie metodą Lemuto z wyborem pivota jako mediana z trzech elementów. Metoda ta jest najskuteczniejsza powyżej wartości $\alpha = 2.0$. Najmniejszą skuteczność ma wybór pivota jako mediana-median z pięciu elementów, przy czym wynik najgorszy osiągnięto dla obydwu metod partycjonowania.\\

Porównując liczbę wykonanych operacji pomiędzy badanymi algorytmami partycjonowania (\ref{fig:quick-sort-deterministic-pivot-all}) można stwierdzić, że partycjonowanie metodą Hoare wykonuje większą liczbę operacji porównania oraz mniejszą liczbę operacji zamiany miejsc. Czynnik ten może okazać się szczególnie istotny w przypadku sortowania złożonych struktur danych.\\
 
Do analizy rozkładu prawdopodobieństwa liczby wykonanych operacji (\ref{fig:quick-sort-deterministic-pivot-density}) użyto tablicy losowych danych o stałym rozmiarze $n = 1000$ oraz współczynnika kosztu o stałej wartości $\alpha = 1.0$. Dla badanych algorytmów najmniejsze odchylenie standardowe mają algorytmy partycjonowania metodą Hoare przy wyborze pivota jako pseudo-mediana z dziewięciu lub mediana-median z trzech. Największe odchylenie standardowe występuje dla klasycznego algorytmu Quick Sort. Najmniejsza wartość oczekiwana liczby wykonanych operacji jest osiągana poprzez patycjonowanie metodą Hoare z wyborem pivota jako ostatni element tablicy.

% tabelka, procentowo średnia liczba wykonanych operacji dla każdej z metod przy stałym rozmiarze tablicy n = 1000
% tabelka, wyliczone odchylenie standardowe oraz wartość oczekiwana dla poszczególnych algorytmów
% Wykres porownujacy roznice pomiedzy przypadkiem srednim a pesymistycznym

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-deterministic-pivot-random.svg}
	\caption[]{}
	\label{fig:quick-sort-deterministic-pivot-random}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-deterministic-pivot-reversed.svg}
	\caption[]{}
	\label{fig:quick-sort-deterministic-pivot-reversed}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-deterministic-pivot-cost-factor.svg}
	\caption[]{}
	\label{fig:quick-sort-deterministic-pivot-cost-factor}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-deterministic-pivot-density.svg}
	\caption[]{}
	\label{fig:quick-sort-deterministic-pivot-density}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=1.1\columnwidth]{img/plot/quick-sort-deterministic-pivot-random-all.svg}
	\caption[]{}
	\label{fig:quick-sort-deterministic-pivot-all}
\end{figure}

\subsection{Wnioski}
W przypadku danych wejściowych typu prostego, tzn. takich, dla których operacja porównania jest czasowo równoważna operacji przypisania, partycjonowanie metodą Hoare okazało się wydajniejsze niż partycjonowanie metodą Lemuto. W przypadku złożonych struktur danych, wydajniejsze jest partycjonowanie metodą Lemuto. Wartość współczynnika kosztu, od której partycjonowanie metodą Lemuto jest bardziej wydajne dla dowolnej strategii wyboru pivota wynosi $\alpha = 2.0$, co można interpretować jako sortowania struktur danych złożonych z co najmniej dwóch typów prostych.\\

Analizując zachowanie algorytmów można stwierdzić, że dla danych posortowanych lub prawie posortowanych, dobrym wyborem jest skorzystanie z kosztownej metody wyszukiwania pivota, która pomimo swojego dodatkowego nakładu czasowego zwiększa prawdopodobieństwo na znalezienie dobrego pivota. Wyjątkiem jest wybór pivota jako mediana-median z pięciu, w przypadku którego dodatkowy nakład czasowy sprawia, że algorytm jest znacznie mniej wydajny nawet dla uporządkowanych danych wejściowych. Przez pojęcie \BOLD{dobrego pivota} rozumiemy tutaj pozycję możliwie blisko środka partycjonowanej tablicy.\\

\section{Rodzina randomizowanych algorytmów Quick Sort}
Klasyczny algorytm Quick Sort kiepsko sobie radzi z uporządkowanymi lub prawie uporządkowanymi danymi wejściowymi. W najmniej skutecznym wariancie, tzn. podczas wyboru pivota jako ostatni element tablicy, algorytm ten działa ze złożonością czasową $O(n^2)$. W przypadku uporządkowanych danych wejściowych skutecznym sposobem może okazać się niedeterministyczny wybór pivota. W tym rozdziale dokonano analizy randomizowanych algorytmów z rodziny Quick Sort, z podziałem na metody partycjonowania Lemuto oraz Hoarego. W analizie wykorzystano następujące metody wyboru pivota:

\begin{itemize}
	\setlength\itemsep{0em}
	\item \BOLD{losowy element} - pivotem jest losowo wybrany element tablicy,
	\item \BOLD{mediana z trzech wyborów} - przystosowanie meotdy \BOLD{power of two choices} do potrzeby wyznaczania mediany, pivotem jest mediana z trzech losowo wybranych elementów,
	\item \BOLD{pseudo-mediana z dziewięciu wyborów} - pivotem jest mediana z dziewięciu losowo wybranych elementów.\\
\end{itemize}

\subsection{Analiza porównawcza algorytmów}
Tak jak w poprzednim rozdziale, algorytmy były analizowane pod kątem liczby wykonywanych operacji atomowych, z podziałem na operacje porównania, zamiany miejsc oraz przypisania. Dodatkowo badano łączny koszt wykonanych operacji jako sumę ważoną liczby operacji atomowych, z uwzględnieniem wartości współczynnika kosztu. Badając łączną liczbę wykonanych operacji założono stałą wartość współczynnika kosztu $\alpha = 1.0$.\\

Dla losowych danych wejściowych (\ref{fig:quick-sort-nondeterministic-pivot-random}), przy założeniu że operacja porównania jest czasowo równoważna operacji przypisania ($\alpha=1.0$), większość randomizowanych metod wyboru pivota okazuje się mniej skuteczna od klasycznego algorytmu Quick Sort. Przy partycjonowaniu metodą Lemuto jedyną skuteczniejszą metodą jest wybór pivota jako mediana z trzech losowych elementów. Przy partycjonowaniu metodą Hoarego, najskuteczniejszym okazuje się wybór za pivota losowego elementu tablicy. Połączenie metody Hoarego z losowym wyborem pivota jest również najskuteczniejszym podejściem podczas sortowania losowych danych. Najmniej wydajną strategią sortowania okazał się wybór pivota jako pseudo-mediana z dziewięciu losowych elementów, przy czym najgorszy wynik osiągnięto dla obydwu metod partycjonowania.\\

Dla danych wejściowych posortowanych w odwrotnej kolejności (\ref{fig:quick-sort-nondeterministic-pivot-reversed}), czyli dla przypadku pesymistycznego w klasycznym algorytmie Quick Sort, przy założeniu że operacja porównania jest czasowo równoważna operacji przypisania ($\alpha=1.0$), najskuteczniejszą strategią sortowania również okazało się partycjonowanie metodą Hoarego przy wyborze pivota jako losowy element tablicy. Spośród randomizowanych strategii sortowania najmniej wydajną okazał się wybór pivota jako pseudo-mediana z dziewięciu losowych elementów. W przypadku danych wejściowych posortowanych w odwrotnej kolejności, każda ze strategii randomizowanych jest wydajniejsza od klasycznego podejścia w metodzie Quick Sort.\\

Analizując łączny koszt wykonanych operacji (\ref{fig:quick-sort-nondeterministic-pivot-cost-factor}) w zależności od wartości współczynnika kosztu $\alpha$ można zauważyć, że dla złożonych typów danych najskuteczniejszą z badanych strategii jest partycjonowanie metodą Lemuto z wyborem pivota jako mediana z trzech losowych elementów. Metoda ta jest najskuteczniejsza powyżej wartości $\alpha = 2.5$, co można interpretować jako sortowanie struktur złożonych z co najmniej trzech typów prostych. Najmniej skuteczną strategią sortowania złożonych struktur jest wybór pivota pseudo-mediana z dziewięciu losowych elementów.\\

Porównując liczbę wykonanych operacji (\ref{fig:quick-sort-nondeterministic-pivot-random-all}) można stwierdzić, że dla dowolnych randomizowanych strategii wyboru pivota, partycjonowanie metodą Hoare wykonuje większą liczbę operacji porównania oraz mniejszą liczbę operacji zamiany miejsc. Tak jak w przypadku algorytmów deterministycznych, czynnik ten może okazać się istotny w przypadku sortowania złożonych struktur.\\

Badając rozkład prawdopodobieństwa liczby wykonanych operacji dla algorytmów randomizowanych (\ref{fig:quick-sort-nondeterministic-pivot-density}) można zauważyć, że algorytmy korzystające z partycjonowania metodą Hoare mają mniejsze odchylenie standardowe niż algorytmy z partycjonowaniem metodą Lemuto. Każdy z randomizowanych algorytmów wyboru pivota daje w wyniku mniejsze odchylenie standardowe od klasycznego algorytmu Quick Sort. Najmniejsze odchylenie standardowe uzyskano dla partycjonowania metodą Hoare z wyborem pivota jako pseudo-mediana z dziewięciu wyborów, jednak równocześnie dla tego algorytmu uzyskano największą wartość oczekiwaną liczby wykonanych operacji. Najmniejszą wartość oczekiwaną uzyskano dla partycjonowania metodą Hoare przy wyborze pivota jako losowy element tablicy.

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-nondeterministic-pivot-random.svg}
	\caption[]{}
	\label{fig:quick-sort-nondeterministic-pivot-random}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-nondeterministic-pivot-reversed.svg}
	\caption[]{}
	\label{fig:quick-sort-nondeterministic-pivot-reversed}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-nondeterministic-pivot-cost-factor.svg}
	\caption[]{}
	\label{fig:quick-sort-nondeterministic-pivot-cost-factor}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-sort-nondeterministic-pivot-density.svg}
	\caption[]{}
	\label{fig:quick-sort-nondeterministic-pivot-density}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=1.1\columnwidth]{img/plot/quick-sort-nondeterministic-pivot-random-all.svg}
	\caption[]{}
	\label{fig:quick-sort-nondeterministic-pivot-random-all}
\end{figure}

\subsection{Wnioski}
W przypadku randomizowanych algorytmów z rodziny Quick Sort, podobnie jak dla algorytmów deterministycznych, partycjonowanie metodą Hoare jest wydajniejsze dla danych wejściowych typu prostego. Należy jednak zauważyć, że partycjonowanie metodą Hoare wykonuje większą liczbę operacji porównania, więc strategia ta jest mniej wydajna w przypadku sortowania złożonych struktur danych. Powyżej wartości współczynnika kosztu równej $\alpha = 4.0$, partycjonowanie metodą Lemuto jest wydajniejsze niż partycjonowanie metodą Hoare, niezależnie od strategii wyboru pivota. Sytuacja ta jest równoważna z sortowaniem struktur składających się z co najmniej czterech zmiennych podstawowych. W tym przypadku należy skorzystać z partycjonowania metodą Lemuto.\\

Analizując liczbę wykonanych operacji można stwierdzić, że w przypadku algorytmów randomizowanych korzystanie z kosztownych strategii wyboru pivota jest nieopłacalne. Najskuteczniejszą metodą, zarówno dla losowych jak i posortowanych danych, okazuje się wybór losowego elementu tablicy.\\


\section{QuickMerge Sort}
% szukamy optymalnego algorytmu dzialajacego w miejscu do sortowania zlozonych sruktor. Poniewaz w przypadku zlozonych struktur, operacja porownania jest znacznie kosztowniejsza niz operacja przypisania, na wstepnie odrzucono partycjonowanie metoda Hoare, ktore dla kazdego przypadku wykonuje wiecej operacji porownania niz metoda Lemuto.

% Z poprzednich analiz wynika, ze partycjonowanie metoda lemuto wykonuje mniej operacji porownania, 
% Eksperymentalne wyznaczanie od którego momentu bardziej się opłaca używać Quick Sort niż Quick Sort, wyliczanie współczynnika na podstawie stosunku kosztu porównania do przypisania

% Analizujac algorytmy Quick Sort można było zauważyć, że Merge sort wykonuje mniej operacji porównania od Quick Sort.
% celem jest znalezienie algorytmu działającego w miejscu, który wykonuje możliwie mało porównań, dlateg wykorzystano partycjonowanie metoda lemuto

Analizując wydajność algorytmów z rodziny Quick Sort badano liczbę wykonywanych operacji atomowych z podziałem na operacje porównania, zamiany miejsc oraz przypisania. Dodatkowo badano łączny koszt wykonanych operacji jako sumę ważoną liczby operacji atomowych, z uwzględnieniem wartości współczynnika kosztu. Badając łączną liczbę wykonanych operacji założono stałą wartość współczynnika kosztu $\alpha = 1.0$.\\

Algorytm QuickMerge Sort to algorytm hybrydowy, w którym podjęto próbę eliminacji klasycznych problemów wynikających ze stosowania algorytmów Quick Sort oraz Merge Sort. 
TODO celem tego algorytmu jest minimalizacja liczby porownan, przy jednoczesnym braku koniecznosci alokowania dodatkowego bufora pamieci.
Głównym problemem algorytmu Quick Sort jest jego słaba złożoność czasowa w przypadku pesymistycznym, równa $O(n^2)$.  W przypadku algorytmu Merge Sort problemem jest konieczność alokacji dodatkowego bufora pamięci.\\ 

Algorytm QuickMerge Sort składa się z ... etapów.
Idea/Koncepcja algorytmu, mocne strony (Merge Sort bez konieczności alokacji pamięci)

\subsection{Pseudokod}

\subsection{Analiza deterministycznych wersji algorytmu QuickMerge Sort}
Ponieważ jednym z kroków algorytmu QuickMerge sort jest partycjonowanie tablicy wejściowej, analizę przeprowadzono z podziałem na deterministyczne oraz randomizowane wersje tego algorytmu.
Dla metod partycjonowania uzyto klasycznej oraz najbardziej skutecznej z poprzedniego rozdzialu.
Analiza algorytmow deterministycznych - najblizej asymptoteycznie jest pseudo-mediana z dziewieciu

Quick Merge sort było partycjonowane metoda lemuto.
Algorytmy były porownywane do Merge Sort oraz do klasycznej metody QUick Sort (metoda Lemuto + pivot ostatni elemet)

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=1.1\columnwidth]{img/plot/quick-merge-sort-deterministic-pivot-random.svg}
	\caption[]{}
	\label{fig:quick-merge-sort-deterministic-pivot-random}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-merge-sort-deterministic-pivot-cost-factor.svg}
	\caption[]{}
	\label{fig:quick-merge-sort-deterministic-pivot-cost-factor}
\end{figure}

\subsection{Analiza randomizowanych wersji algorytmu QuickMerge Sort}
Tak jak w poprzednim rozdziale, w analizie porownawczej nie uwzgledniono algorytmow partycjonowania metoda Hoare, poniewaz metoda ta wykonje wiecej operacji porownania.
W analizie porownawczej wykorzystano klasyczny alorytm Merge Sort oraz Quick Sort z wyborem pivota jako losowy element tablicy.

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=1.1\columnwidth]{img/plot/quick-merge-sort-nondeterministic-pivot-random.svg}
	\caption[]{}
	\label{fig:quick-merge-sort-nondeterministic-pivot-random}
\end{figure}

\begin{figure}[]
	\centering
	\includesvg[inkscapelatex=false,width=0.8\columnwidth]{img/plot/quick-merge-sort-nondeterministic-pivot-cost-factor.svg}
	\caption[]{}
	\label{fig:quick-merge-sort-nondeterministic-pivot-cost-factor}
\end{figure}

\subsection{Wnioski}
Wyniki analizy porównawczej


\section{Intro Sort}
Ogólny opis algorytmu, gdzie jest wykorzystywany (std::sort w g++), zalety.
% TODO sprawdzic jakiego algorytmu partycjonowania uzywaja w srodku i spróbować podmienić, zmienic na wariacje z randomowym
% wyborem pivota
\subsection{Pseudokod}

\subsection{Analiza eksperymentalna algorytmu}
Wykresy liczby wykonywanych operacji w porównaniu do algorytmów bazowych.
Wykresy gęstości liczby wykonywanych operacji dla stałej liczby n, np n = 10000.
Wykresy dla różnych algorytmów partycjonowania.

\subsection{Wnioski}
Wyniki analizy porównawczej

% TODO jak zdaze proba modyfikacji algorytmu intro sort

% TODO jak zdaze dodac Quick Heap Sort

% TODO merge sort na wiele czesci
